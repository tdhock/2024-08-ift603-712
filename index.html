
<!-- ssaved from url=(0068)./index.html -->
<html><head>
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8">

<title>UdeS IFT 603/712 Automne 2024</title>


<style>
/* unvisited link */
a:link { 
    color: #000000;
}

/* visited link */
a:visited {
    color: #000000;
}

/* mouse over link */
a:hover {
    color: #cbcbcb;
}

/* selected link */
a:active {
    color: #000000;
}

body {color:#464646;font-family:sans-serif;}
hr {
 color: #cbcbcb;
}
hst {
    text-decoration: line-through;
}

</style>
</head>
<body bgcolor="#FFFFFF" leftmargin="0" topmargin="0" marginwidth="0" marginheight="0">
			
			<br><br>
			
			<table id="Tableau_03" width="940" border="0" cellpadding="0" cellspacing="20" bordercolor="cbcbcb" bgcolor="#ffffff">
			<tbody><tr><td align="left" valign="top">
			

			      <font size="5"><b>UdeS IFT603/712: Techniques d'Apprentissage, automne 2024</b></font><br><br>
			      <font size="4">Création de cours : <a href="https://jodoin.github.io/">Pierre-Marc Jodoin</a>,<br>
				modifications pour automne 2024 : Toby Dylan HOCKING.</font>			      <br><br>

			<font size="4"><b>Objectifs du cours</b></font><br>
			<hr align="left" width="85%">
			
<p align="justify">
L’apprentissage automatique ou l’apprentissage par machine (<i>Machine Learning</i>) s'intéresse à la conception, l'analyse, l'implémentation et l’application de programmes capables de s’améliorer, au fil du temps, soit sur la base de leur propre expérience, soit à partir des données d'apprentissage. De nos jours, l’apprentissage automatique joue un rôle essentiel dans de nombreux domaines d’applications, tels que la vision par ordinateur, le traitement automatique du langage, la reconnaissance vocale, les systèmes tutoriels intelligents, la modélisation de l’usager, la robotique, la bio-informatique, les finances, le marketing, les jeux vidéos, la télédétection, etc. En fait, la plupart des programmes de l’intelligence artificielle contiennent un module d’apprentissage. Presque tous les systèmes de reconnaissances de formes sont basés sur des techniques d’apprentissage.
</p>


			<br><font size="4"><b>Manuel</b></font><br>
			<hr align="left" width="85%">
			
<p>
	    Il est possible de réussir le cours sans acheter le manuel de référence.  Cependant, il est <b>recommandé</b> d'en faire l'achat car le cours en est tiré.  Bien que ce livre date de quelques années déjà, c'est une excellente référence pour comprendre les bases des techniques d'apprentissage.
		Le livre de référence est  <a href="https://www.amazon.ca/gp/r.html?C=1JDTYWBDK5ZYA&R=23JFUCXFL7PO9&T=C&U=https%3A%2F%2Fwww.amazon.ca%2FPattern-Recognition-Machine-Learning-Christopher%2Fdp%2F0387310738%2Fref%3Dcm_sw_em_r_dp_w_da_Z1azyb42CFTF5_tt&A=YPAQJN5AWLHNLWKXFJ8XELY0HGMA&H=GLWDX9FBUFF4AVUODIVRBSWRSS8A">Pattern
		Recognition and Machine Learning</a> de Christopher M. Bishop.   Il est possible de le commander sur Amazon. Une copie est également à
		la <a href="http://www.usherbrooke.ca/biblio/infogen/bibliotheques/bibliotheque-des-sciences-et-de-genie/">bibliothèque
		des sciences et de génie</a>.<br><br>
		
	Pour ceux et celles qui ne rechignent pas à l'idée de lire un livre sur un écran d'ordinateur, le manuel de Bishop est disponible en <a href='./BishopBook.pdf'> format pdf </a>.<br><br>

	Un autre très bon manuel de référence est <a href="https://www.amazon.ca/dp/B083M7DBP6/ref=cm_sw_em_r_mt_dp_1A7SBA8CZ1QJ54P2J2M2">Mathematics for Machine Learning</a> par Deisenroth, Faisal et Ong.  Je recommande tout particulièrements les chapitres 2 à 6 pour ceux et celles qui souhaitent revoir les notions de base requisent pour ce cours en algèbre linéaire, probabilités et calcul différentiel et intégral.  Ce manuel est également disponible gratuitement <a href='./mml-book.pdf'>en ligne</a>.
</p>

			<br><font size="4"><b>Méthode pédagogique</b></font><br>
			<hr align="left" width="85%">
			
<p>
La méthode pédagogique employée pour ce cours diffère de celles de la plus part des cours magistraux universitaires.  En effet, à chaque semaine, vous serez invité à visionner de 60 à 90 minutes de vidéos en ligne.  <b>Il est important de visionner ces vidéos car elles couvrent environ 70% de la matière totale du cours</b>.  L'horaire des vidéo est donnée dans le tableau ci-bas. 
</p><p>

Lors des séances magistrales en classe, je reverrai avec vous certains concepts mathématiques de base parfois oubliés (vous vous souvenez des probabilités conditionnelles?
des vecteurs propres? de la dérivée en cha&icirc;ne?) ainsi que certaines preuves mathématiques en lien avec la matière vue dans les vidéos ainsi que des mise en contexte et des exercices pratiques et théoriques.  Cette méthode pédagogique fait suite à de nombreux commentaires émis par les étudiants.es au fil des années.  Cette approche pédagogique a donc pour objectif de vous aider!
</p><p>
Les séances magistrales devraient prendre une à deux heures par semaine.  Vous serez également invités à poser des questions quant à la matière vue dans les vidéos.  L'heure restante sera passée au laboratoire pour vous aider avec les travaux pratiques (autre requête formulées par les élèves des années antérieures).

</p>



			<br><font size="4"><b>Notes de cours et vidéos à visualiser à la maison</b></font><br>

			<hr align="left" width="95%">

	<table cellspacing="0" width=620 border=1>
	      <tbody><tr bgcolor="#999999">
        <td width="120px" align="center"><font color="#000"><b>Semaine</b></font></td> 
		<td width="405px" align="center"><font color="#000"><b>Contenu</b></font></td> 
		<td width="40px" align="center"><font color="#000"><b>Sections<br> du livre</b></font></td>
              </tr>
	     <tr bgcolor="#fbfbfb">
		     <td> Semaine 0 <br> (à faire par soi-même au besoin)</td>
             <td><b> Mise à niveau</b><br>
                       &#8194;•  <a href="https://www.learnpython.org/">Tutoriel Python avec interface en ligne</a><br>
                        &#8194;• <a href="https://docs.python.org/3/tutorial/">Tutoriel Python approfondi</a><br>
                       &#8194;•  <a href="http://cs231n.github.io/python-numpy-tutorial/">Tutoriel Python - Stanford</a><br>
 
		     
		      &#8194;• <a href="http://www.youtube.com/watch?v=tdouYphUi-w">Dérivées</a><br>
		      &#8194;• <a href="http://www.youtube.com/watch?v=HniO8Apx95A">Dérivées partielles</a><br>
              &#8194;• Algèbre linéaire (<a href="https://mml-book.github.io/book/mml-book.pdf">sections 2.1,2.2,2.3.1,2.3.4,4.2)</a> <br>
              &#8194;• Stats et prob de base (<a href="https://mml-book.github.io/book/mml-book.pdf">sections 6.1 à 6.5</a>) 
		    </td> 
		    <td align="right">
		      1.2.4, 2.1, 2.3, Apprendix C
		    </td>
			</tr>
			  
		    	  
	     <tr bgcolor="#dddddd">
             <td> Semaine 1 </td>

             <td><b>0- Presentation </b> [<a href="./notes/00_presentation_2pages.pdf">pdf</a>]
                              [<a href="./notes/00_presentation_3pages.pdf">pdf</a>]
                              <br>
                <b>1- Concepts fondamentaux</b> [<a href="./notes/01_concepts_fondamentaux_2pages.pdf">pdf</a>]
		[<a href="./notes/01_concepts_fondamentaux_3pages.pdf">pdf</a>]
		[<a href="./ipython_notebook/Concepts_fondamentaux.ipynb">ipython notebook</a>]
		
            <br><br>Evaluation/CV et plus proche voisins : 
		[<a href="https://github.com/tdhock/2023-08-deep-learning/blob/main/slides/02-cross-validation.pdf">Hocking CV pdf</a>]
		[<a href="https://github.com/tdhock/2023-08-deep-learning/blob/main/slides/03-nearest-neighbors.pdf">Hocking nearest neighbors pdf</a>]
	    [<a href="https://github.com/tdhock/2024-08-ift603-712/tree/main/cv-evaluation-examples">Resultats sur 19 jeux de données</a>]
	    [<a href="cv-evaluation-examples/zipUSPS_error_algos_mean_SD.png">zipUSPS</a>]
	    [<a href="cv-evaluation-examples/NSCH_autism_error_algos_mean_SD.png">NSCH_autism</a>]
	    [<a href="cv-evaluation-examples/zz_error_minutes_4_data.png">Quatre jeux de données, taux d'erreur et temps de calcul</a>]
	    [<a href="https://tdhock.github.io/blog/2024/viz-pred-err/">Visualisation du test de Student (T-test)</a>]
	    <br>
		Interactives :
		[<a href="https://tdhock.github.io/2020-02-03-capacity-polynomial-degree/">polynome surapprentissage</a>]
		[<a href="https://tdhock.github.io/2023-12-04-capacity-polynomial-degree-several-patterns/">polynome surapprentissage + plusieurs jeux de données</a>]
		[<a href="https://tdhock.github.io/2023-12-04-degree-neighbors/">polynome surapprentissage + voisins</a>]
		[<a href="https://tdhock.github.io/2019-01-nearest-neighbor-regression-one-split/">voisins surapprentissage</a>]
            <br><br>
            <a href="https://www.youtube.com/watch?v=dauUhCvDJ8w&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=2&t=0s">Présentation 0</a> (2:19)<br>
            <a href="https://www.youtube.com/watch?v=pN0_4iV3v_A&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=3&t=0s">Présentation 1</a> (20:27)<br>
            <a href="https://www.youtube.com/watch?v=gBxiz-OL0bI&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=4&t=0s">Concepts fondamentaux 0</a> (11:12)<br>
            <a href="https://www.youtube.com/watch?v=AUtZp21xeU8&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=5&t=0s">Concepts fondamentaux 1</a> (18:33)<br>
            <a href="https://www.youtube.com/watch?v=s9O4gq49N9g&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=6&t=0s">Concepts fondamentaux 2</a> (9:52)<br>
            <a href="https://www.youtube.com/watch?v=26vUFa1i7OI&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=7&t=0s">Concepts fondamentaux 3</a> (8:19)<br>
            <a href="https://www.youtube.com/watch?v=4HyvuSr4nRY&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=8&t=0s">Concepts fondamentaux 4</a> (8:07)<br>
            
		    </td> 
		    <td align="right">
		      1.0, 1.1, 1.3
		    </td>
			</tr>
			  
		<tr bgcolor="#fbfbfb">
            <td> Semaine 2 </td>
			<td><b>2- Formulation probabiliste</b> [<a href="./notes/02_formulation_probabiliste_2pages.pdf">pdf</a>] 
			[<a href="./notes/02_formulation_probabiliste_3pages.pdf">pdf</a>] 
			[<a href="./ipython_notebook/Formulation_probabiliste.ipynb">ipython notebook</a>]<br>
            <br>

		     <a href="https://www.youtube.com/watch?v=tAvSzBpDLj8&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=9&t=0s">Formulations probabilistes 0</a> (19:57)<br>
		     <a href="https://www.youtube.com/watch?v=VVfkEhveZt8&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=10&t=0s">Formulations probabilistes 1</a> (23:49)<br>
		     <a href="https://www.youtube.com/watch?v=n2f7nZMBhB0&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=11&t=0s">Formulations probabilistes 2</a> (20:16)<br>
		     <a href="https://www.youtube.com/watch?v=a9sPYKit2WI&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=12&t=0s">Formulations probabilistes 3</a> (11:38)<br>
		    </td> 
		    <td align="right">
		      1.2,  1.2.1, 1.2.2, 1.2.4, 1.2.5, 1.6, 1.6.1
		    </td>
		</tr>
			  
		
		<tr bgcolor="#dddddd">
            <td> Semaine 3 </td>
	    <td><b>3- Régression linéaire</b> [<a href="./notes/03_regression_lineaire_2pages.pdf">pdf</a>]
	      [<a href="./notes/03_regression_lineaire_3pages.pdf">pdf</a>]
	      [<a href="https://github.com/tdhock/2023-08-deep-learning/blob/main/slides/09-regression.pdf">Hocking regression pdf</a>]
            	[<a href="./ipython_notebook/Regression.ipynb">ipython notebook</a>]<br> 
            <br><br>
                     
            <a href="https://www.youtube.com/watch?v=AV3fco1UQGE&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=13&t=0s"> Régression linéaire 0</a> (10:29)<br>
            <a href="https://www.youtube.com/watch?v=IGmX6l2dsn8&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=14&t=0s"> Régression linéaire 1</a> (16:04)<br>
            <a href="https://www.youtube.com/watch?v=gKIRhpXJrMo&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=46&t=0s"> Régression linéaire 2</a> (11:04)<br>
            <a href="https://www.youtube.com/watch?v=d036Z3p_g7Y&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=15&t=0s"> Régression linéaire 3</a> (7:11)<br>
            <a href="https://www.youtube.com/watch?v=vtuyyAj7q18&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=16&t=0s"> Régression linéaire 4</a> (5:03)<br>
            <a href="https://www.youtube.com/watch?v=xygPFZtZh5Q&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=17&t=0s"> Régression linéaire 5</a> (5:32)<br>
		    </td> 
		    <td align="right">
		      3.1, 3.1.1, 3.1.4, 3.1.5, 3.2<br>
		    </td>
		</tr>
			  
			
		<tr bgcolor="#fbfbfb">
            <td> Semaine 4</td>
			<td><b>4- Classification linéaire</b> [<a href="./notes/04_classification_lineaire_2pages.pdf">pdf</a>] 
			[<a href="https://github.com/tdhock/2023-08-deep-learning/blob/main/slides/04-linear-models.pdf">Hocking pdf</a>] 
			[<a href="./notes/04_classification_lineaire_3pages.pdf" color='FF0000'>pdf</a>]
			[<a href="./ipython_notebook/Classification_lineaire.ipynb">ipython notebook</a>]<br>
		    <a href="https://www.youtube.com/watch?v=JfVYiJshWaA&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=19&t=0s"> Classification linéaire 0</a> (7:03)<br>
		    <a href="https://www.youtube.com/watch?v=BJH-4ZCj6ZY&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=20&t=0s"> Classification linéaire 1</a> (7:40)<br>
		    <a href="https://www.youtube.com/watch?v=2u89bs1AldI&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=21&t=0s"> Classification linéaire 2</a> (12:05)<br>
		    <a href="https://www.youtube.com/watch?v=ldkJNPOP9zA&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=22&t=0s"> Classification linéaire 3</a> (13:05)<br>
		    <a href="https://www.youtube.com/watch?v=XlmjL1YqhPY&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=23&t=0s"> Classification linéaire 4</a> (37:17)<br>
		    </td> 
		    <td align="right">
		      4.1, 4.1.2, 4.1.3, 4.1.4, 4.2, 4.3, 
		    </td>
		</tr>
		
		<tr bgcolor="#dddddd">
            <td> Semaine 5</td>
			<td><b>4- Classification linéaire</b> [<a href="./notes/04_classification_lineaire_2pages.pdf">pdf</a>] 
			[<a href="./notes/04_classification_lineaire_3pages.pdf" color='FF0000'>pdf</a>]
			[<a href="./ipython_notebook/Classification_lineaire.ipynb">ipython notebook</a>]<br>
            <br>
            <a href="https://www.youtube.com/watch?v=8tYkG8I7uC8&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=24&t=0s"> Classification linéaire 5</a> (39:01)<br>
		    <a href="https://www.youtube.com/watch?v=9FhwHkBbf-0&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=25&t=0s"> Classification linéaire 6</a> (6:01)<br>
		    <a href="https://www.youtube.com/watch?v=7mcsmYYZNX4&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=26&t=0s"> Classification linéaire 7</a> (12:01)<br>
		   
		    <b>NOTE:</b> le tp2 comporte une question en lien avec la notion de "Lagrangien".  Bien que nous verrons cette notion en classe, vous pouvez visionner ces deux vidéos qui introduisent très bien cette notion et donnent quelques exemples d'application:<br>
		    <a href="https://www.youtube.com/watch?v=ry9cgNx1QV8"> Lagrangien 1</a>(9:56)<br>
		    <a href="https://www.youtube.com/watch?v=q8y_O-AlUkQ"> Lagrangien 2</a>(31:55)

		    </td> 
		    <td align="right">
		      4.1, 4.1.2, 4.1.3, 4.1.4, 4.2, 4.3, 
		    </td>
		</tr>
		
		
		<tr bgcolor="#fbfbfb">
            <td> Semaine 6</td>		    
		    <td>
		      <b>5- Méthodes à noyau</b> [<a href="./notes/05_methodes_a_noyaux_2pages.pdf">pdf</a>] 
			  [<a href="./notes/05_methodes_a_noyaux_3pages.pdf">pdf</a>] 
               [<a href="./ipython_notebook/Methodes_a_noyaux.ipynb">ipython notebook</a>]<br> 
            <br><br>


            <a href="https://www.youtube.com/watch?v=LkpfqzbVJEc&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=27&t=0s"> Méthodes à noyau 0</a> (28:53)<br>  
            <a href="https://www.youtube.com/watch?v=5n0VmAOM4Ns&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=28&t=0s"> Méthodes à noyau 1</a> (9:49)<br>  
            <a href="https://www.youtube.com/watch?v=pFOA8sUKk7k&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=29&t=0s"> Méthodes à noyau 2</a> (10:11)<br>  
		    
            </td> 
		    <td align="right">
		      6.1, 6.2
		    </td>
        </tr>
		
	
		<tr bgcolor="#dddddd">
            <td> Semaine 7</td>
		    
		    <td>
		      <b>6- SVM (Séparateur à Vaste Marge / Machines à vecteurs de support)</b>  [<a href="./notes/06_machine_vecteurs_support_2pages.pdf">pdf</a>]
			   [<a href="./notes/06_machine_vecteurs_support_3pages.pdf">pdf</a>]
            <br><br>


            <a href="https://www.youtube.com/watch?v=vqKY06s_CAo&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=30&t=0s"> Machines à vecteurs de support 0</a> (20:02)<br>  
            <a href="https://www.youtube.com/watch?v=iA1sR4bWUY8&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=31&t=0s"> Machines à vecteurs de support 1</a> (15:31)<br>  
            <a href="https://www.youtube.com/watch?v=uenfwkqPr84&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=32&t=0s"> Machines à vecteurs de support 2</a> (11:32)<br>  
		    
            </td> 
		    <td align="right">
		      7.0, 7.1, 7.1.1, 7.1.2
		    </td>
        </tr>
		 
	    <tr bgcolor="#fbfbfb">
            <td> Semaine 8</td>
		    
			<td><b>Examen périodique</b>
		    </td> 
		    <td align="right">
		    </td>
		</tr>

        <tr bgcolor="#dddddd">
            <td> Semaine 9</td>
		    
			<td><b>Semaine de lecture</b>
		    </td> 
		    <td align="right">
		    </td>
		</tr>

	
				<tr bgcolor="#fbfbfb">
                <td> Semaine 10 </td>
		    
		    <td>
		      <b>7- Réseaux de neurones multi-couches</b>
		      [<a href="./notes/07_MLP_2pages.pdf">pdf</a>] 
		      [<a href="./notes/07_MLP_3pages.pdf">pdf</a>] 
		      [<a href="https://github.com/tdhock/2023-08-deep-learning/blob/main/slides/torch-part1/06-backprop.pdf">Hocking pdf</a>] 
              <br><br>
              <a href="https://www.youtube.com/watch?v=jFNJ1aEU2mM&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=33&t=0s"> Réseaux de neurones multi-couches 0</a> (8:02)<br>
              <a href="https://www.youtube.com/watch?v=8vTLUxhG4hU&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=34&t=0s"> Réseaux de neurones multi-couches 1</a> (17:08)<br>
              <a href="https://www.youtube.com/watch?v=F5odzNmRpDY&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=35&t=0s"> Réseaux de neurones multi-couches 2</a> (12:40)<br>
              <a href="https://www.youtube.com/watch?v=Ueo4ZL8A-4s&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=36&t=0s"> Réseaux de neurones multi-couches 3</a> (3:35)<br>
              <a href="https://www.youtube.com/watch?v=pwfaPxslMAI&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=37&t=0s"> Réseaux de neurones multi-couches 4</a> (13:46)<br>
              <a href="https://www.youtube.com/watch?v=p4lgzWvgAiI&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=38&t=0s"> Réseaux de neurones multi-couches 5</a> (11:50)<br>
		    </td> 
		    <td align="right">
		      5.1, 5.2, 5.2.1, 5.2.4, 5.3, 5.3.1, 5.3.2, 5.5
		    </td>
        </tr>
			  

	<tr bgcolor="#dddddd">
		<td> Semaine 11</td>
		    
		    <td>
		      <b>7- Réseaux de neurones multi-couches</b> 
              <br><br>

              <a href="https://www.youtube.com/watch?v=ycbZOIAfN6Q&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=39&t=0s"> Réseaux de neurones multi-couches 6</a> (44:03)<br>
              <a href="https://www.youtube.com/watch?v=C9Gd3AprnlQ&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=40&t=0s"> Réseaux de neurones multi-couches 7</a> (12:53)<br>
	      <a href="https://www.youtube.com/watch?v=zodMaaZJy7g&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=41&t=0s"> Réseaux de neurones multi-couches 8</a> (28:47)<br><br>
	  <!-- 
	      <b><a href="https://www.youtube.com/watch?v=iQL_QJ4rlUY&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=55"> rétro-propagation 0</a> (8:17)<br>
	      <a href="https://www.youtube.com/watch?v=TnvifgbE_z8&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=56"> rétro-propagation 1</a> (26:39)<br>
	      <a href="https://www.youtube.com/watch?v=XM-Qi8DGp1U&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=57"> rétro-propagation 2</a> (15:12)<br>
	      <a href="https://www.youtube.com/watch?v=r_yUsOIAr-U&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=58"> rétro-propagation 3</a> (19:32)<br>
	      <a href="https://www.youtube.com/watch?v=9OInn9q4F9A&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=59"> rétro-propagation 4</a> (12:47)<br>
	      <a href="https://www.youtube.com/watch?v=6WACOTYCHT0&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=60"> rétro-propagation 5</a> (13:57)<br>
	  -->
		    
		    </td> 
		    <td align="right">
		      5.1, 5.2, 5.2.1, 5.2.4, 5.3, 5.3.1, 5.3.2, 5.5
		    </td>
        </tr>
			  

	    <tr bgcolor="#fbfbfb">
		    <td> Semaine 12</td>
		    <td> <b>8- Combinaison de modèles </b> [<a href="./notes/08_combinaison_de_modeles_2pages.pdf">pdf</a>]
			[<a href="./notes/08_combinaison_de_modeles_3pages.pdf">pdf</a>] 
            [<a href="./ipython_notebook/Combinaison_de_modeles.ipynb">ipython notebook</a>]<br><br>
            
            <a href="https://www.youtube.com/watch?v=rasxq1hkPTA&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=42&t=0s"> Combinaison de modèles 0</a> (13:08)<br>
            <a href="https://www.youtube.com/watch?v=LpLcCeq-t-I&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=43&t=0s"> Combinaison de modèles 1</a> (21:50)<br>
            <a href="https://www.youtube.com/watch?v=mNjdRpafB1Y&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=44&t=0s"> Combinaison de modèles 2</a> (11:47)<br>
            <a href="https://www.youtube.com/watch?v=O9ANAliVMLg&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=45&t=0s"> Combinaison de modèles 3</a> (2:30)<br>
	    <a href="https://www.youtube.com/watch?v=Bt1EoQsbTyQ&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=46&t=0s"> Combinaison de modèles 4</a> (21:12)<br><br>
	    </td> 
		    <td align="right">
		      14.0, 14.2, 14.3, 14.3.1
		    </td>
        </tr>
	
	
	<tr bgcolor="#dddddd">
            <td> Semaine 13</td>
		    
		    <td>
		      <b>9- Théorie de la décision</b> [<a href="./notes/09_theorie_decision_2pages.pdf">pdf</a>] 
			  [<a href="./notes/09_theorie_decision_3pages.pdf">pdf</a>] 
              <br><br>
            <a href="https://www.youtube.com/watch?v=5XCpibBm-o0&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=54&t=0s"> Théorie de la décision 0</a> (25:49)<br>
            <a href="https://www.youtube.com/watch?v=9teqXYbJ8k0&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=55&t=0s"> Théorie de la décision 1</a> (16:29)<br>
		    </td> 
		    <td align="right">
		      1.5.5, 3.2
		    </td>
        </tr>
		    		
		<tr bgcolor="#fbfbfb">
            <td> Semaine 14</td>
            <td><b>10- Mélange de gaussiennes </b> [<a href="./notes/10_melange_de_gaussiennes_2pages.pdf">pdf</a>] 
			[<a href="./notes/10_melange_de_gaussiennes_3pages.pdf">pdf</a>]
	      [<a href="https://github.com/tdhock/2023-08-unsupervised-learning/blob/main/slides/03-gaussian-mixtures.pdf">Hocking pdf</a>]
            <br><br>
            <a href="https://www.youtube.com/watch?v=EGKkSlf8V9w&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=47&t=0s"> Mélange de gaussiennes 0</a> (11:04)<br>
            <a href="https://www.youtube.com/watch?v=48mCPrIDS0k&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=48&t=0s"> Mélange de gaussiennes 1</a> (8:27)<br>
            <a href="https://www.youtube.com/watch?v=G5EebrlXKG8&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=49&t=0s"> Mélange de gaussiennes 2</a> (12:25)<br>
            <a href="https://www.youtube.com/watch?v=Rg__D-63cPU&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=50&t=0s"> Mélange de gaussiennes 3</a> (14:19)<br>
            
            </td> 
		    <td align="right">
		      <br>
		      9.2,9.4
		      
		    </td>
              </tr>

		<tr bgcolor="#dddddd">
            <td> Semaine 15</td>
            <td><b>10- Mélange de gaussiennes </b> 
            <br><br>
            <a href="https://www.youtube.com/watch?v=uGaMqdY2aM8&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=51&t=0s"> Mélange de gaussiennes 4</a> (11:13)<br>
            <a href="https://www.youtube.com/watch?v=pcK9ABi_enk&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=52&t=0s"> Mélange de gaussiennes 5</a> (13:53)<br>
            <a href="https://www.youtube.com/watch?v=S89HZBTx8VI&list=PLRsdyg1KyVVdnQbSd7ejhY8X8qV8Hie1r&index=53&t=0s"> Mélange de gaussiennes 6</a> (14:13)<br>

            
            
            </td> 
		    <td align="right">
		      <br>
		      9.2,9.4
		      
		    </td>
              </tr>
  
		</table>
		 <br><br><font size="4"><b>Travaux Pratiques</b></font><br>
			<hr align="left" width="95%">
			Veuillez utiliser <b><a href="https://turnin.dinf.usherbrooke.ca/">turninweb</a></b> pour soumettre vos travaux. Tout retard ou erreur de remise entra&icirc;nera une pénalité de 10% par jour et une note de 0 après 5 jours.  <br>  Veuillez également utiliser la plateforme de développement "gitlab" de l'Université.  Pour ce faire, connectez-vous une première fois à <a href="https://depot.dinf.usherbrooke.ca/"> depot.dinf.usherbrooke.ca </a> et 12 heures plus tard vous pourrez commencer à travailler.  Si vous ne pouvez créer de projet 12 heures après vous être connecté, envoyer un courriel à l'administrateur système <a href="mailto:Daniel-Junior.Dube@USherbrooke.ca">Daniel-Junior Dubé</a> afin qu'il aide.  <br><br>
			Pour connaître vos <font="red"> <b>partenaires d'équipes</a></font>, veuillez consulter le <a href="https://docs.google.com/spreadsheets/d/19urfulqOJ7DGyU7_eWcwARNfR1m2Ih08ZQ-3hT5-JJ0/edit?usp=sharing">document que voici</a>.
		

		<br><br>
		<b>NOTE IMPORTANTE 1</b></b> : En plus de votre code, veuillez soumettre un fichier <b>"gitlab.txt"</b> dans lequel vous donnez le lien vers votre dépôt sur <a href="https://depot.dinf.usherbrooke.ca">le gitlab du département d'informatique</a>.<br>
		<b>NOTE IMPORTANTE 2</b> : En plus de vos documents de travail, vous devez remplir, signer et joindre à votre travail le formulaire d'intégrité que voici : <a href="https://docs.google.com/document/d/1-raKfIQleF6UWe0MsuegT9JnDhjhbxNdSpbaFXadJP0/edit?usp=sharing"> formulaire d'intégrité</a></b>.<br>
		<b>NOTE IMPORTANTE 3</b> : En plus de vos documents de travail, vous devez remplir et joindre à votre travail l'agenda d'équipe que voici : <a href="https://docs.google.com/spreadsheets/d/1VVsGbUnHBbLhmscHSMmCIrPjn7GgZrnmXE_9xCvVu0Q/edit?usp=sharing"> agenda d'équipe</a>
	<br>    <b>NOTE IMPORTANTE 4</b> : veuillez bien utiliser git car une mauvaise utilisation pourra entraîner une <b> perte de points aux TP3 et TP4 ainsi que pour le projet (ift712)</b>.
	<br>    <b>NOTE IMPORTANTE 5</b> : avant de commencer à travailler sur vos TP, veuillez svp prendre connaissance du document que voici : <a href="recommandatonsTP.pdf"> recommandatonsTP.pdf </a>	
	<br><br>
		
<table border="0" cellpadding="2" cellspacing="2" width=600>

    <tbody>
        <tr> <td width="100">Setup</td> <td> <a href="./demos/python_setup.pdf"> Aide à la mise sur pied d'un environnement virtuel python sous Linux</a></td><td> <a href="./demos/requirements.txt">requirements.txt</a><br><a href="./demos/bashrc.txt">bashrc.txt</a><br>           			
			<br>
	
	</tr>
    <tr> <td width="100">Tp1</td> <td><a href="./demos/tp1/tp1.pdf">Description (remise : 2 février)</a> </td><td> <a href="./demos/tp1/progTP1.zip"> code</a> <a href="./demos/tp1/bareme1.pdf">bareme</a><br> </tr>
    <tr> <td width="100">Tp2</td> <td><a href="./demos/tp2/tp2.pdf">Description (remise : 23 février)</a> </td><td> <a href="./demos/tp2/progTP2.zip"> code</a> <a href="./demos/tp2/bareme2.pdf">bareme</a> </td></tr>
    <tr> <td width="100">Tp3</td> <td><a href="./demos/tp3/tp3.pdf">Description (remise : 15 mars)</a> </td><td> <a href="./demos/tp3/progTP3.zip"> code</a> <a href="./demos/tp3/bareme3.pdf">bareme</a> </td></tr>
    <tr> <td width="100">Tp4</td> <td><a href="./demos/tp4/tp4.pdf">Description (remise : 15 avril)</a> </td><td> <a href="./demos/tp4/progTP4.zip"> code</a> <a href="./demos/tp4/bareme4.pdf">bareme</a></td></tr>
    <tr> <td width="100"></td>    <td><a href="./softmax_grad.html">Le softmax et son gradient : kit de survie!</a> </td><td> </td></tr> 
    <tr> <td width="100">Projet-ift712</td><td>Voir plan de cours (remise : 15 avril)</td><td>  </a></td></tr>

    </tbody>

</table>

<br><br><font size="4"><b>Examens (exemples)</b>(NOTE : l'examen final est récapitulatif)</font><br>
<hr align="left" width="85%">

<table border="0" cellpadding="2" cellspacing="2">

<tbody>
<tr> <td width=350><b>Intra1</b></td> <td><a href="intraIFT603_pratique.pdf">intra1.pdf</a> </td></tr>
<tr> <td width=350><b>Intra2</b></td> <td><a href="intraIFT603_pratique2.pdf">intra2.pdf</a> </td></tr>
<tr> <td width=350><b>Final </b></td> <td><a href="finalIFT603_pratique.pdf">final.pdf</a></td></tr> 
 </td> </tr>
</tbody></table>


			</td><td width="240" valign="top">  <font color="#000000"> <b>Sommaire</b></font><hr align="left" width="70%">
	

			<font color="#89bc23" size="3"> Professeur</font><br>
			Toby Dylan HOCKING<br><br>

			<font color="#89bc23" size="3"> Correcteur</font><br>
			<a href="mailto:Jeremi.Levesque@usherbrooke.ca">Jeremi Lévesque</a>
            <br><br>
			
			<font color="#89bc23" size="3"> Périodes de cours</font><br>
			Le mercredi de 10h30 à 11h20, D7-2023<br>
			Le jeudi de 10h30 à 12h20, D7-2023<br><br>
			
			<font color="#89bc23" size="3"> Période de disponibilités</font><br>
			Du lundi au vendredi de 9h30 à 16h30 <br><br>


			<font color="#89bc23" size="3"> Horaire et plan de cours</font><br>
			<a href="./plan_de_coursIFT603_712.pdf">(plan ift603-712)</a>  <br><br>
 
 

  </td></tr>
			
			</tbody></table>
			
			</center>

			</td>
		</tr></tbody></table></body></html>
